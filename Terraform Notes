Commands to Manage Workspaces
ğŸ”¹ 1. Create a New Workspace
terraform workspace new <workspace_name>


Example:

terraform workspace new dev

ğŸ”¹ 2. List All Workspaces
terraform workspace list


ğŸ”¹ The current workspace is marked with an asterisk (*).

ğŸ”¹ 3. Switch to an Existing Workspace
terraform workspace select <workspace_name>


Example:

terraform workspace select dev

ğŸ”¹ 4. Show Current Workspace
terraform workspace show

ğŸ”¹ 5. Delete a Workspace

(Only possible if the workspace is not currently selected)

terraform workspace delete <workspace_name>

âš ï¸ Notes

The default workspace is always present.

Workspaces isolate state files, not resources themselves unless your configuration (e.g., backend or resource names) accounts for the workspace name.

Best practice: Use terraform.workspace in resource naming or backend configuration to fully isolate resources across workspaces.


** 
Great! Hereâ€™s a full example of how to use terraform.workspace in your Terraform configuration to manage isolated environments like dev, stage, and prod using workspaces.

âœ… Goal

We'll create an S3 bucket with a name that changes based on the current workspace, so each workspace creates its own isolated resource.

ğŸ“ Example: main.tf
provider "aws" {
  region = "us-east-1"
}

resource "aws_s3_bucket" "example" {
  bucket = "my-app-bucket-${terraform.workspace}"
  acl    = "private"

  tags = {
    Environment = terraform.workspace
  }
}

output "bucket_name" {
  value = aws_s3_bucket.example.bucket
}


Steps to Use It
1. Initialize Terraform
terraform init

2. Create and Switch to a Workspace
terraform workspace new dev


(or switch to an existing one)

terraform workspace select dev

3. Apply the Configuration
terraform apply


ğŸ”¸ This will create an S3 bucket named my-app-bucket-dev.

4. Switch to Another Workspace
terraform workspace new prod
terraform apply

This creates a separate bucket like my-app-bucket-prod.

Each workspace maintains its own state, so the dev and prod buckets won't conflict or overwrite each other.

Important Notes

You must ensure that resource names (like S3 buckets) are unique across workspaces, especially for global resources (S3 bucket names must be globally unique in AWS).

Use terraform.workspace in tags, names, or logic to customize resources per environment.




***
Great â€” letâ€™s extend the setup to include workspace-specific variables and show how to configure different backends per workspace if needed.

ğŸ¯ Goal

We'll:

Use different values (e.g. tags or instance types) depending on the workspace.

Optionally configure workspace-aware backends (e.g. different S3 state files per workspace).

1ï¸âƒ£ Workspace-Specific Variables Using locals

You can use a locals block to change values based on the current workspace.

ğŸ”¸ Example with EC2 instance type:
locals {
  instance_type_map = {
    dev     = "t2.micro"
    staging = "t3.micro"
    prod    = "t3.large"
  }

  instance_type = lookup(local.instance_type_map, terraform.workspace, "t2.micro")
}

resource "aws_instance" "example" {
  ami           = "ami-0c55b159cbfafe1f0" # Use your region's latest Amazon Linux 2 AMI
  instance_type = local.instance_type

  tags = {
    Environment = terraform.workspace
  }
}


So:

dev â†’ t2.micro

prod â†’ t3.large

Defaults to t2.micro if workspace not listed.

2ï¸âƒ£ Different Terraform State Backends per Workspace (Optional Advanced)
âš ï¸ Caution

Terraform does not support dynamic backends (i.e. using terraform.workspace directly in backend blocks). But you can manually separate state per workspace by using key patterns in the backend configuration.

ğŸ”¸ Example: backend.tf
terraform {
  backend "s3" {
    bucket = "my-terraform-state-bucket"
    key    = "env/${terraform.workspace}/terraform.tfstate"
    region = "us-east-1"
  }
}

ğŸš¨ But this wonâ€™t work directly!

Because the backend block is evaluated before any variables or functions like terraform.workspace.

âœ… Workaround: Use CLI Workspaces + Pre-Set Backend Files

You can:

Create separate backend-<workspace>.tf files for each workspace.

Use them like:

terraform init -backend-config=backend-dev.tf
terraform workspace select dev

ğŸ“ backend-dev.tf
bucket = "my-terraform-state-bucket"
key    = "env/dev/terraform.tfstate"
region = "us-east-1"


Repeat for backend-prod.tf, backend-staging.tf, etc.

âœ… Summary
Feature	Terraform Support	Notes
terraform.workspace	âœ… Yes	Use in resource names, tags, locals
Dynamic backends	âŒ No	Workaround with separate backend config files per workspace
Workspace-specific variables	âœ… Yes	Use locals + maps + lookup()



** IMPORT FROM AWS CONSOLE **

Absolutely. Letâ€™s walk through a complete example: how to import a manually created AWS resource into Terraform step by step, with a real Terraform .tf file example.

âœ… Scenario Example: Import a Manually Created AWS EC2 Instance

Letâ€™s say:

You manually launched an EC2 instance via the AWS Console

Its instance ID is i-0123456789abcdef0

You now want to bring it under Terraform control

ğŸ”§ Step-by-Step: Importing AWS Resource into Terraform
ğŸŸ¢ Step 1: Create a Terraform Resource Block

First, create a minimal Terraform resource block for the EC2 instance in your Terraform configuration.

ğŸ“„ main.tf

provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "imported_ec2" {
  # No arguments yet; Terraform will not use this to change anything yet.
  # We'll fill in the actual attributes after importing.
}

ğŸŸ¢ Step 2: Initialize Terraform (if not already done)
terraform init

ğŸŸ¢ Step 3: Import the EC2 Instance into Terraform State

Use the EC2 instance's ID from the AWS Console.

terraform import aws_instance.imported_ec2 i-0123456789abcdef0


âœ… This adds the EC2 instance to your .tfstate file, so Terraform knows it exists.

ğŸŸ¢ Step 4: Review the Imported Resource

Run:

terraform state show aws_instance.imported_ec2


Youâ€™ll get output like this:

# aws_instance.imported_ec2:
resource "aws_instance" "imported_ec2" {
  ami                          = "ami-0c55b159cbfafe1f0"
  instance_type                = "t2.micro"
  subnet_id                    = "subnet-abc123"
  vpc_security_group_ids       = ["sg-0abc123"]
  associate_public_ip_address  = true
  key_name                     = "my-keypair"
  tags = {
    Name = "ManuallyCreatedEC2"
  }
}

ğŸŸ¢ Step 5: Update the .tf File with Actual Attributes

Now, modify your main.tf resource to match the real configuration of the instance:

resource "aws_instance" "imported_ec2" {
  ami                    = "ami-0c55b159cbfafe1f0"
  instance_type          = "t2.micro"
  subnet_id              = "subnet-abc123"
  vpc_security_group_ids = ["sg-0abc123"]
  associate_public_ip_address = true
  key_name               = "my-keypair"

  tags = {
    Name = "ManuallyCreatedEC2"
  }
}

ğŸŸ¢ Step 6: Run terraform plan to Confirm No Drift
terraform plan


If your .tf file matches the state and real AWS resource, the plan will show:

No changes. Your infrastructure matches the configuration.

âœ… Success â€” the resource is now under Terraform management!

âœ… Summary Table
Step	Command / Action	Purpose
1	Create resource block in .tf	Define structure for imported resource
2	terraform init	Initialize Terraform
3	terraform import <resource> <id>	Import AWS resource into state
4	terraform state show <resource>	View imported attributes
5	Update .tf file	Match actual resource configuration
6	terraform plan	Confirm sync between code and AWS
ğŸ” Bonus: Import Other AWS Resources
AWS Resource	Terraform Type	Example Command
S3 Bucket	aws_s3_bucket	terraform import aws_s3_bucket.mybucket my-console-bucket
IAM Role	aws_iam_role	terraform import aws_iam_role.myrole my-iam-role-name
Security Group	aws_security_group	terraform import aws_security_group.sg sg-0123abcd


** Import from one module to another module ** 
how to import or pass one module into another module in terraform
In Terraform, modules are isolated and don't automatically share resources or outputs. However, you can pass values from one module to another using output variables and input variables â€” effectively "connecting" modules through the root module (your main config).

âœ… Goal

You cannot directly "import" one module into another, but you can pass data between them like this:

module A (produces output) â†’ root module â†’ module B (receives input)
ğŸ“Œ Step-by-Step: Pass One Module's Output to Another Module
ğŸ”¹ 1. Module A: Define an Output

Let's say Module A creates a VPC and outputs the VPC ID.

# modules/vpc/main.tf
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

output "vpc_id" {
  value = aws_vpc.main.id
}

ğŸ”¹ 2. Root Module: Call Module A and Capture the Output
# main.tf
module "vpc" {
  source = "./modules/vpc"
}


Now module.vpc.vpc_id is available in the root module.

ğŸ”¹ 3. Module B: Accept the Input as a Variable

Let's say Module B creates a subnet inside the VPC.

# modules/subnet/variables.tf
variable "vpc_id" {
  type = string
}

# modules/subnet/main.tf
resource "aws_subnet" "main" {
  vpc_id     = var.vpc_id
  cidr_block = "10.0.1.0/24"
}

ğŸ”¹ 4. Root Module: Pass Output from Module A to Module B
# main.tf
module "subnet" {
  source = "./modules/subnet"
  vpc_id = module.vpc.vpc_id
}

âœ… Result

Youâ€™ve now passed a value from Module A to Module B using the root module as a bridge.

ğŸ§  Terraform Does Not Support:

âŒ Importing one module directly into another

âŒ Calling one module inside another module like a nested function

Terraform modules are intended to be self-contained and composable, and the root module acts as the orchestrator.

âœ… Visual Summary
[ Module A ] ---> outputs ---> [ Root Module ] ---> inputs ---> [ Module B ]

ğŸ” Real-World Use Case Example

Module A: Creates VPC

Module B: Creates subnets using VPC ID from Module A

Module C: Creates EC2 instances in subnets from Module B

Everything is wired through the root module, using:

output in the source module

input variable in the destination module

module.<name>.<output> in root module


** what is the difference between terraform import and terraform taint ?
The terraform import and terraform taint commands in Terraform are used for very different purposes. Here's a clear comparison to help you understand the difference:

terraform import :

Purpose:
To bring existing infrastructure under Terraform management.

Use Case:
You have an existing resource (e.g., an AWS EC2 instance, an S3 bucket) that was created outside of Terraform, and you want Terraform to manage it.

What it does:

Associates a real-world resource with a resource in your Terraform configuration.

Updates the Terraform state file with information about the existing resource.

Does NOT create or modify the infrastructure.

You still need to write the matching Terraform configuration manually.

Example:

terraform import aws_instance.my_instance i-0abcd1234efgh5678


This tells Terraform: â€œThe EC2 instance with ID i-0abcd1234efgh5678 should now be managed as aws_instance.my_instance.â€

ğŸ”§ terraform taint

Purpose:
To mark a resource for destruction and recreation on the next terraform apply.

Use Case:
A resource is in a bad state, or you want to force it to be re-created, even if its configuration hasnâ€™t changed.

What it does:

Marks the specified resource as tainted in the state file.

On the next terraform apply, Terraform will destroy and re-create the resource.

Example:

terraform taint aws_instance.my_instance


This tells Terraform: â€œRecreate this instance the next time I run terraform apply, even if nothing about it has changed.â€

ğŸ” Summary Comparison
Feature	terraform import	terraform taint
Main Purpose	Bring existing resource into Terraform	Force recreation of a resource
Affects Infrastructure?	No (just updates the state file)	Yes (destroys and recreates resource)
Needs Config Block?	Yes, must already exist in the code	Yes, resource must be in configuration
Common Use Case	Adopting existing infra into Terraform management	Replacing a broken/misbehaving resource


**
how do you manage secrets in terraform without hardcoding them ?
Great question! Managing secrets securely in Terraform is critical to protecting your infrastructure. Hardcoding secrets in Terraform files (like .tf or .tfvars) is strongly discouraged.

Here are the best and most secure ways to manage secrets in Terraform without hardcoding them:

âœ… 1. Use Environment Variables

Set sensitive values like API keys or cloud provider credentials as environment variables.

In Terraform:
You can reference environment variables using the TF_VAR_ prefix.

Example:

export TF_VAR_db_password="super-secret-password"


In your Terraform code:

variable "db_password" {
  type      = string
  sensitive = true
}

resource "aws_db_instance" "example" {
  ...
  password = var.db_password
}


Marking it as sensitive = true hides it from plan/apply output.

âœ… 2. Use a .tfvars File (With .gitignore!)

You can store secrets in a separate .tfvars file and never commit it to version control.

Example: secrets.auto.tfvars

db_password = "super-secret-password"


Protect it:
Add this to .gitignore:

*.tfvars

âœ… 3. Use a Secret Management Tool

This is the most secure and scalable option, especially in production environments.

ğŸ” Options include:
Tool	Description
HashiCorp Vault	First-class integration with Terraform. Use the Vault provider
 or fetch secrets at runtime.
AWS Secrets Manager	Store secrets in AWS and fetch them using the AWS provider or data sources.
Azure Key Vault	Fetch secrets via Terraform's azurerm_key_vault_secret data source.
Google Secret Manager	Similar integration with GCP secrets.

Example with AWS Secrets Manager:

data "aws_secretsmanager_secret_version" "db_password" {
  secret_id = "my_db_password"
}

resource "aws_db_instance" "example" {
  password = data.aws_secretsmanager_secret_version.db_password.secret_string
}

âœ… 4. Use Terraform Cloud or Terraform Enterprise Variables

If you're using Terraform Cloud or Enterprise, you can store sensitive variables securely in the workspace settings.

Mark them as sensitive, and they will be encrypted and hidden in logs.

âœ… 5. Use sensitive = true in Terraform Code

Even if you securely load secrets, always mark them as sensitive in your variable blocks:

variable "api_key" {
  type      = string
  sensitive = true
}


This prevents the value from being shown in terraform plan or terraform apply output.

âŒ Avoid These Bad Practices:

âŒ Hardcoding secrets directly in .tf files

âŒ Committing secrets to version control

âŒ Leaving unencrypted .tfvars in shared storage

ğŸ§ª Bonus Tip: Combine with CI/CD Secrets Management

Use your CI/CD pipeline's secrets store (e.g., GitHub Actions Secrets, GitLab CI, CircleCI, etc.) to inject environment variables or terraform.tfvars securely at runtime.


** Count vs for_each **

âœ… Terraform count vs for_each
ğŸ”¢ count

Creates multiple identical resources.

Accepts a number.

Access each resource using count.index.

Simple and good for repeating the same resource.

ğŸ” for_each

Creates resources from a set or map.

Use each.key and each.value to access elements.

Supports customization of each resource.

More flexible and stable if your inputs change.

ğŸ— Real-World Scenario:

You want to create EC2 instances for dev, test, and prod environments.

With count, we'll just repeat the same instance N times.

With for_each, weâ€™ll assign different instance types for each environment.

ğŸ“˜ Example 1: Using count
â• Goal:

Create 3 identical EC2 instances named dev, test, and prod.

ğŸ“„ Terraform Code (Using count)
provider "aws" {
  region = "us-east-1"
}

variable "envs" {
  default = ["dev", "test", "prod"]
}

resource "aws_instance" "example" {
  count         = length(var.envs)
  ami           = "ami-0c55b159cbfafe1f0"  # Amazon Linux 2
  instance_type = "t2.micro"

  tags = {
    Name = var.envs[count.index]
  }
}

ğŸ§¾ Explanation:

count = 3 creates three EC2 instances.

We use count.index to access each environment name (dev, test, prod).

All instances are of type t2.micro.

ğŸ–¨ Output Example:
output "instance_ids" {
  value = aws_instance.example[*].id
}

Output:
instance_ids = [
  "i-01abc123dev",
  "i-02def456test",
  "i-03ghi789prod"
]

âš ï¸ Limitation:

If you remove "test" from the list, "prod"'s index changes, and Terraform destroys and recreates the "prod" instance. Not ideal.

ğŸ“˜ Example 2: Using for_each
â• Goal:

Create EC2 instances for each environment with a custom instance type.

ğŸ“„ Terraform Code (Using for_each)
provider "aws" {
  region = "us-east-1"
}

variable "instances" {
  default = {
    dev  = "t2.micro"
    test = "t3.micro"
    prod = "t3.medium"
  }
}

resource "aws_instance" "example" {
  for_each      = var.instances
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = each.value

  tags = {
    Name = each.key
    Env  = each.key
  }
}

ğŸ§¾ Explanation:

for_each iterates over a map.

each.key is the environment (dev, test, prod).

each.value is the instance type (t2.micro, etc.).

Each EC2 instance is customized per environment.

ğŸ–¨ Output Example:
output "instance_ids" {
  value = {
    for env, instance in aws_instance.example :
    env => instance.id
  }
}

Output:
instance_ids = {
  "dev"  = "i-01abc123"
  "test" = "i-02def456"
  "prod" = "i-03ghi789"
}

âœ… Advantages:

Easy to customize each resource.

If you remove "test", only that instance is destroyed.

"prod" remains unaffected â€” no resource shifting.

ğŸ§¾ Summary Table
Feature	count	for_each
Input type	Number	Set or Map
Access	count.index	each.key, each.value
Custom resource config	âŒ Harder	âœ… Easy
Resource stability	âŒ Can shift on list change	âœ… Stable due to key-based mapping
Best for	Identical resources	Unique/named resources
âœ… When to Use What?
Use Case	Use
3 EC2s with the same config	count
EC2s with different instance types	for_each
Want resource stability on changes	for_each
Want simpler iteration	count


** how do you handle drift detection in terraform ? **
Great question â€” drift detection is an essential part of managing infrastructure with Terraform.

ğŸ” What is Drift?

Drift happens when the real-world infrastructure (e.g., in AWS, Azure, GCP) changes outside of Terraform, so it no longer matches whatâ€™s in your Terraform state file.

Examples:

Someone manually changes an EC2 instance type in the AWS Console.

A resource is deleted outside of Terraform.

A setting is modified via an API or CLI.

ğŸ§° How to Handle Drift Detection in Terraform
âœ… 1. Run terraform plan regularly
terraform plan


Terraform compares the actual infrastructure with the Terraform state.

If it detects any drift, it shows what would change on terraform apply.

Pros:

Simple and built-in.

Works well for teams doing IaC properly.

Cons:

Doesnâ€™t track why drift happened.

Doesnâ€™t notify you unless you run it manually or via CI/CD.

âœ… 2. Use terraform apply with no changes
terraform apply


Shows and optionally fixes drift.

Can be run in automation (e.g., nightly job) to auto-heal drift.

âœ… 3. Enable Drift Detection in Terraform Cloud or Terraform Enterprise

If you're using Terraform Cloud or Enterprise, it has automatic drift detection built-in.

It monitors for changes outside of Terraform.

Alerts you when drift is detected.

Allows you to reconcile via a run.

Terraform Cloud UI:

Navigate to the workspace â†’ Drift Detection tab.

You can even configure notifications (Slack, email, etc.).

âœ… 4. Manually Reconcile Drift

If terraform plan detects drift:

You can choose to apply and bring it back to the declared config.

Or, if the external change is correct, update your Terraform code to reflect it.

âœ… 5. Use terraform state commands for inspection

If a resource was deleted manually, you might need to remove it from the state:

terraform state list
terraform state show <resource>
terraform state rm <resource>


Then re-import it or re-create it properly via Terraform.

âœ… 6. Implement Guardrails and IAM Permissions

Prevent drift in the first place by:

Limiting who can make manual changes.

Using policy-as-code (e.g., with Sentinel or OPA).

Setting up alerting on changes via cloud provider tools (e.g., AWS CloudTrail).

ğŸš¨ What Terraform Canâ€™t Detect

Terraform does not track or detect drift automatically unless:

You run terraform plan or apply, or

You use Terraform Cloud with drift detection enabled.

Drift in data sources is not considered "drift" because theyâ€™re read-only.

ğŸ§ª Bonus: CI/CD-Based Drift Detection

Set up a nightly or scheduled job to run:

terraform init
terraform plan -detailed-exitcode


Exit code 0: No changes

Exit code 2: Drift detected (plan has changes)

Exit code 1: Error

This allows you to alert or log drift automatically.

âœ… Summary
Method	Drift Detection?	Auto-Fix?	Notes
terraform plan	âœ… Yes	âŒ No	Manual; best used regularly
terraform apply	âœ… Yes	âœ… Yes	Applies the fixes
Terraform Cloud	âœ… Yes (Auto)	âŒ No	Detects and alerts, but doesn't apply
Scheduled CI/CD Plan	âœ… Yes	âŒ No	Great for automation
IAM / Cloud Auditing	âŒ Preventative	âŒ No	Helps prevent but doesnâ€™t detect

** terraform refresh vs terraform plan **
Great question! While terraform refresh and terraform plan may seem similar because both involve checking the real state of infrastructure, they serve different purposes in Terraform workflows.

ğŸ†š terraform refresh vs terraform plan
Feature	terraform refresh	terraform plan
Purpose	Updates the Terraform state file with the real infrastructure state	Shows what Terraform will do to reconcile desired and actual state
Modifies State?	âœ… Yes â€“ updates the local state	âŒ No â€“ only reads the state and shows changes
Makes Changes to Infra?	âŒ No	âŒ No (but can suggest changes)
Output	Silent update to state (no plan output)	Shows a plan of actions: add, change, destroy
Used When?	You suspect drift and want to update state manually	You want to preview changes before applying
Preferred?	Rarely used directly in newer workflows	âœ… Used daily before terraform apply
ğŸ”„ terraform refresh
ğŸ“Œ What it does:

Queries all remote resources defined in your Terraform state.

Updates the local state file to match the real infrastructure.

Does not change your .tf code or infrastructure.

ğŸ§ª Use case:

You manually changed something in the cloud and want the state file to reflect it without changing your code.

Useful in debugging or scripting, but rarely needed in standard workflows.

ğŸ“¦ Example:
terraform refresh


ğŸ“ After running it, you can run terraform show to see the updated state.

ğŸ“‹ terraform plan
ğŸ“Œ What it does:

Compares:

Your Terraform config (.tf files),

The current Terraform state file, and

The actual infrastructure.

Shows what actions (if any) would be taken by terraform apply.

ğŸ§ª Use case:

Before applying any changes, always run terraform plan to preview what will happen.

ğŸ“¦ Example:
terraform plan


ğŸ“ Output might look like:

~ resource "aws_instance" "example" {
    instance_type = "t2.micro" -> "t3.micro"
}


This shows Terraform will change the instance type.

ğŸ” Typical Workflow (Modern Terraform)
terraform init      # Initialize
terraform plan      # Preview changes
terraform apply     # Apply changes


âš ï¸ terraform refresh is implicitly run as part of terraform plan and terraform apply in Terraform v0.15+ â€” so you usually don't need to run it separately.

âœ… Summary Table
Task	refresh	plan
Updates Terraform state?	âœ… Yes	âŒ No
Makes changes to cloud?	âŒ No	âŒ No
Shows what will change?	âŒ No	âœ… Yes
Typically run manually?	âŒ Rarely	âœ… Yes (always)
Run automatically in plan/apply?	âœ… Yes (as of v0.15+)	âœ… Yes
ğŸ” When should I use refresh?

Only when:

You want to update the state manually.

You're troubleshooting.

You use terraform state commands in automation or scripts.

Otherwise, stick with plan for your day-to-day workflow.

** how do you safely rollback infrastructure changes after a failed deployment ? **

Rolling back infrastructure after a failed deployment in Terraform is not as straightforward as with some application deployment tools, because Terraform doesnâ€™t support automatic rollback out of the box. However, there are safe and practical strategies to manage or simulate rollback behavior.

ğŸš¨ Why Rollback is Tricky in Terraform

Terraform is declarative â€” you describe the desired state.

It doesnâ€™t keep a "previous good state" to automatically revert to.

If a change fails mid-deployment, some resources may have changed, and some may not â€” leading to partial updates or drift.

âœ… Strategies to Safely Roll Back Infrastructure Changes
âœ… 1. Use terraform plan + apply carefully

The first defense against needing a rollback is preventing bad deployments:

Always run:

terraform plan


to preview changes before applying.

Use manual terraform apply, or gated CI/CD pipelines with approvals.

âœ… 2. Version your Terraform code (Git)

If a deployment fails or breaks something:

You can revert the code to a previous known-good Git commit.

Then re-apply it to roll back the desired state.

git checkout <previous-good-commit>
terraform apply


Terraform will compare the current state to the old config and make changes to match the previous working version.

âœ… 3. Use Terraform Cloud/Enterprise with State History

Terraform Cloud (or Enterprise) automatically keeps historical state snapshots.

You can view and download a previous state version.

Use terraform state push to manually restore a previous state if needed (advanced and risky if misused).

âœ… 4. Manually Revert Resources

If a resource was updated incorrectly, you can:

Revert the .tf configuration manually to the previous values.

Run:

terraform apply


to bring the infrastructure back in line.

This is essentially a manual rollback â€” youâ€™re telling Terraform to return things to how they were.

âœ… 5. Use Feature Toggles / Blue-Green / Canary Deployments

For zero-downtime or safer changes, especially in production:

Use blue-green deployment strategies:

Deploy new infra alongside existing.

Shift traffic (e.g., with load balancers).

Delete old infra only after verifying success.

Use feature flags or canaries to reduce blast radius.

This avoids the need for immediate rollback and increases confidence.

âœ… 6. Create Manual State Backups Before Critical Changes

Before major changes, run:

cp terraform.tfstate terraform.tfstate.backup


If a critical failure happens and you know what you're doing, you can use:

terraform state push terraform.tfstate.backup


âš ï¸ Only do this with extreme caution. You're forcibly overwriting the state.

âŒ What Not to Do
Action	Why Itâ€™s Risky
Deleting resources manually	Causes drift â€” Terraform wonâ€™t track it
Editing state manually (JSON)	Can corrupt your state file
Applying code without planning	Might break more things
ğŸ§¾ Summary
Strategy	Safe Rollback?	When to Use
Revert code in Git + apply	âœ… Yes	Most common and safe
Use Terraform Cloud state history	âœ… Yes	With Terraform Cloud or Enterprise
Manually revert .tf configuration	âœ… Yes	When you know what needs reverting
Restore old state file (state push)	âš ï¸ Risky	Only for experts in critical cases
Blue-green / canary deployments	âœ… Yes	For production & critical systems
ğŸ’¡ Pro Tip

Always test changes in lower environments before deploying to production, and use CI/CD pipelines with plan approval gates to minimize risk.






**  terraform refresh vs terraform import **
Excellent question! Let's dive into the differences between terraform refresh and terraform import, as they serve very different purposes in Terraform.

ğŸ†š Terraform refresh vs import
Feature	terraform refresh	terraform import
Purpose	Syncs the Terraform state with real infrastructure	Brings existing resources into Terraform state
Modifies .tf config?	âŒ No	âŒ No (must write config manually)
Modifies state file?	âœ… Yes (updates real values from provider)	âœ… Yes (adds resource to state)
Creates resources?	âŒ No	âŒ No
Used for?	Detecting drift, syncing state	Managing external resources with Terraform
Common use case	Resync state after manual changes in cloud	Adopt existing cloud resources into Terraform
ğŸ”„ terraform refresh
ğŸ“Œ Purpose:

Update the Terraform state file to match the real-world infrastructure, without changing the infrastructure or config.

ğŸ§ª Use Case:

You suspect manual changes were made outside of Terraform and want to update the state to reflect them before running plan or apply.

ğŸ“¦ Example:
terraform refresh


This fetches the latest info from your cloud provider and updates the local state file (e.g., if an EC2 tag was changed manually).

ğŸ§  Note:

In Terraform 0.15+, refresh is run automatically as part of terraform plan and apply, so it's rarely needed on its own.

ğŸ“¥ terraform import
ğŸ“Œ Purpose:

Add an existing infrastructure resource (e.g., EC2 instance, S3 bucket) into Terraform's state so that it can be managed by Terraform.

ğŸ§ª Use Case:

You created a resource manually or using another tool and now want to manage it with Terraform.

ğŸ“¦ Example:

Suppose you have an EC2 instance with ID i-1234567890abcdef0:

terraform import aws_instance.my_ec2 i-1234567890abcdef0


This adds the resource to the state, under aws_instance.my_ec2, but:

â—ï¸ You must still write the matching Terraform code:

resource "aws_instance" "my_ec2" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"
  # Must match actual configuration of the real instance
}

ğŸ§¾ Key Differences
Feature	terraform refresh	terraform import
Syncs resource attributes?	âœ… Yes	âœ… Yes (on import)
Adds new resources to state?	âŒ No	âœ… Yes
Needs resource block in .tf?	âœ… Yes (already present)	âœ… Must be added manually
Changes infrastructure?	âŒ No	âŒ No
Used for drift detection?	âœ… Yes	âŒ No
Used for adoption of resources?	âŒ No	âœ… Yes
ğŸ¯ When to Use What?
Situation	Use
A resource exists outside of Terraform	terraform import
You suspect manual changes in infrastructure	terraform refresh
You want Terraform to take control of a resource	terraform import
You want the state file to match the real state	terraform refresh
ğŸ§  Final Tip

Often, you'll use both together:

terraform import to add a resource to state.

terraform refresh (or plan) to ensure state reflects the real infrastructure.

** How does terraform handle state locking , and what happens if the lock is lost mid-apply ?  **
Terraform state locking is a safety mechanism to prevent concurrent operations from corrupting the same state file. Hereâ€™s how it works and what really happens if a lock disappears during an apply.

How Terraform handles state locking
1. When locking happens

Terraform automatically attempts to acquire a lock when you run commands that can modify state, such as:

terraform apply

terraform plan -out=...

terraform destroy

terraform import

Read-only commands like terraform plan (without -out) usually do not lock.

2. Where the lock lives (backend-dependent)

Locking is implemented by the backend, not Terraform Core itself:

Backend	Locking mechanism
Local	OS-level file lock on terraform.tfstate
S3	DynamoDB table (recommended)
AzureRM	Azure Blob Lease
GCS	Object preconditions
Terraform Cloud / Enterprise	Remote lock service

If a backend does not support locking, Terraform will warn you.

3. Whatâ€™s in a lock

A lock record typically contains:

Operation type (apply, destroy)

Who holds the lock (user / hostname)

Terraform version

Timestamp

This helps with troubleshooting and safe recovery.

What happens if the lock is lost mid-apply?

This is rare but important to understand.

Scenario 1: Lock is lost, but the apply continues

Examples:

Network interruption

Backend service hiccup

Lock TTL expires (some backends)

What Terraform does:

Terraform keeps running the apply

It does not immediately stop or roll back

Resources may continue to be created, updated, or destroyed

Risk:
Another user or CI job could start a new apply at the same time, leading to:

State corruption

Duplicate resources

Conflicting updates

Scenario 2: Terraform process crashes after resources were changed

If Terraform crashes or is killed:

Some infrastructure changes may already exist

State may be partially updated or not updated at all

This results in state drift:

Real infrastructure â‰  Terraform state

Is Terraform â€œtransactionalâ€?

No.

Terraform does not provide atomic or rollback-style transactions:

It applies changes incrementally

There is no automatic undo if something fails

State updates happen as resources succeed

How Terraform tries to protect you

State is written incrementally after successful resource operations

Failed resources are not recorded as successful

Providers attempt idempotent operations where possible

Still, lost locks are considered a dangerous condition.

What to do if a lock is lost or stuck
1. First: verify no apply is running

Check:

CI jobs

Other users

Terraform Cloud runs

Cloud provider activity logs

2. If the lock is stuck

Use:

terraform force-unlock <LOCK_ID>


âš ï¸ Only do this if you are 100% sure no apply is running.

3. After a mid-apply failure

Run:

terraform plan


Possible outcomes:

Terraform detects drift and wants to fix it

Terraform wants to recreate resources that already exist

Terraform wants to destroy partially-created resources

You may need:

terraform import

terraform state rm

Manual provider cleanup (last resort)

Best practices to avoid lock problems

Always use a backend with locking

For S3: enable DynamoDB locking

Avoid -lock=false (almost never safe)

Run Terraform from CI/CD, not multiple laptops

Keep applies short and well-scoped

Monitor backend availability

TL;DR

Terraform locks state to prevent concurrent writes

Locking is backend-specific

If a lock is lost mid-apply, Terraform does not stop

Concurrent applies can corrupt state

Recovery usually involves plan, import, or manual cleanup

If you want, I can walk through a real-world failure scenario (like S3 + DynamoDB) and show exactly how to recover safely.

Great â€” hereâ€™s a concrete, real-world walkthrough using the most common setup:

Terraform backend: S3 + DynamoDB state locking

Iâ€™ll show:

Normal locking behavior

How the lock gets lost mid-apply

What breaks

Safe recovery steps (what to do and not do)

1. Normal flow (what should happen)
Backend config
backend "s3" {
  bucket         = "tf-state-prod"
  key            = "network/terraform.tfstate"
  region         = "us-east-1"
  dynamodb_table = "terraform-locks"
}

Apply starts
terraform apply


Terraform:

Writes a lock item to DynamoDB

Reads current state from S3

Computes the plan

Starts creating resources

Updates state in S3 as each resource succeeds

Removes the lock at the end

âœ… Safe and serialized.

2. How a lock gets lost mid-apply
Common causes

Network interruption between Terraform and DynamoDB

CI runner crashes or is evicted

DynamoDB table misconfigured (TTL enabled âŒ)

Manual deletion of the lock item

IAM permission issue during apply

Letâ€™s walk through the dangerous one.

3. Failure scenario: lock lost, apply still running
Timeline

T0

terraform apply


Lock acquired in DynamoDB

Apply begins

T1
Terraform creates:

VPC âœ…

Subnets âœ…

Security groups âœ…

State is being written incrementally to S3.

T2 â€“ Problem

Network glitch

DynamoDB lock item disappears

Terraform does NOT stop

Terraform:

Keeps applying

Still modifying infrastructure

Still writing state updates

âš ï¸ Terraform does not re-check the lock continuously

T3 â€“ Second apply starts
Another engineer or CI job runs:

terraform apply


Since the lock is gone:

Terraform successfully acquires a new lock

Reads state (which may be partially updated)

Now you have two applies running concurrently.

4. What can break (real consequences)
Example outcomes
Duplicate resources

Two load balancers created

Two IAM roles with different names

One referenced, one orphaned

State corruption

Apply A creates resource

Apply B doesnâ€™t see it in state

Apply B tries to create it again â†’ error or duplicate

Partial failures

Resources exist in AWS

Terraform state doesnâ€™t know about them

This is how teams end up with:

â€œTerraform wants to recreate everythingâ€

â€œResource already existsâ€ errors

Manual cleanup emergencies

5. Terraform crashes after resources were created

Now suppose:

Apply A crashes

Lock is gone

Infrastructure was partially created

State is incomplete

At this point:

Terraform has no memory of what succeeded

AWS does

This is called state drift.

6. Safe recovery procedure (step-by-step)
Step 1: STOP all applies

Cancel CI jobs

Tell teammates to pause

Do not run apply yet

Step 2: Inspect the lock table

Check DynamoDB:

Is there a lock?

Is anyone actively applying?

If no apply is running, proceed.

Step 3: Force unlock (only if safe)
terraform force-unlock <LOCK_ID>


âš ï¸ Never do this if an apply might still be running.

Step 4: Run a plan
terraform plan


Now Terraform will show one of these:

Case A: Drift detected

Terraform wants to:

Recreate resources that already exist

Destroy things it thinks are wrong

âœ… This is normal after a failed apply.

Step 5: Fix state vs reality

You have 3 main tools:

1ï¸âƒ£ Import existing resources
terraform import aws_lb.app alb-123456


Use when:

Resource exists

Terraform wants to recreate it

2ï¸âƒ£ Remove broken state entries
terraform state rm aws_instance.bad


Use when:

State references something that no longer exists

3ï¸âƒ£ Manual cleanup (last resort)

Only if:

Resource is junk

Not referenced elsewhere

Safe to delete

Step 6: Re-plan and apply
terraform plan
terraform apply


At this point:

State and reality should converge again

7. What not to do

âŒ Donâ€™t rerun apply immediately
âŒ Donâ€™t use -lock=false
âŒ Donâ€™t delete the state file
âŒ Donâ€™t guess â€” always plan first

8. How to prevent this in production
Critical best practices

Never enable TTL on the DynamoDB lock table

One apply at a time (CI enforced)

Terraform Cloud or Enterprise if possible

Short applies (small modules)

Separate state per environment

Monitoring on failed CI applies

Key takeaway

Terraform locking is best-effort protection, not a transaction system.

If a lock is lost mid-apply:

Terraform keeps going

You can get concurrent applies

Recovery is possible, but requires care

If you want, I can:

Show a DynamoDB lock table schema

Walk through Terraform Cloud behavior

Explain why TTL on locks is dangerous

Simulate a recovery decision tree

** explain a real scenario where terraform plan shows no change, but apply still modifies resources. **

This does happen in real systems, and itâ€™s one of the most confusing Terraform behaviors. Letâ€™s walk through concrete, production-grade scenarios where:

terraform plan shows â€œNo changesâ€, but
terraform apply still modifies real infrastructure

Iâ€™ll explain why Terraform thinks nothing will change, what actually changes, and how to detect and prevent it.

Core idea (why this is possible)

Terraform planning is based on:

State file (what Terraform believes exists)

Provider read data (what the provider can see)

Static configuration

During apply, Terraform:

Re-reads some values

Re-evaluates unknowns

Executes provider logic that may mutate resources implicitly

Terraform is not purely declarative at runtime.

Scenario 1: Provider-side defaults applied at apply time (VERY common)
Example: AWS Security Group rules
resource "aws_security_group" "app" {
  name = "app-sg"

  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

What happens

terraform plan:

No changes. Infrastructure is up-to-date.


terraform apply:

AWS reorders rules

Adds implicit fields (like self = false)

Normalizes CIDRs

Provider sends a full rule set anyway

ğŸ”§ Result:
AWS updates the security group even though nothing changed logically.

Why plan didnâ€™t show it

Providerâ€™s Read() normalizes values

Providerâ€™s Update() still sends a full replacement set

AWS API treats it as a modification

Scenario 2: Computed values change between plan and apply
Example: timestamp() or uuid()
resource "aws_launch_template" "lt" {
  name = "app-${timestamp()}"
}

Behavior

terraform plan:

Function is evaluated

Value is marked known

No diff

terraform apply:

Function re-evaluated

Value differs

Launch template replaced

âš ï¸ Terraform does not guarantee identical evaluation between plan and apply for time-based functions.

Scenario 3: Data source changes after planning
Example: AMI lookup
data "aws_ami" "latest" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*"]
  }
}

Timeline

terraform plan â†’ AMI ami-aaaa

New AMI released

terraform apply â†’ AMI ami-bbbb

Terraform sees:

Plan was valid at the time

Apply uses fresh data

ğŸ’¥ Resource updates even though plan said no changes.

Scenario 4: Drift that plan cannot detect
Example: Manual change that matches schema but differs semantically
IAM policies

Whitespace or ordering changes

JSON normalized differently

resource "aws_iam_policy" "p" {
  policy = jsonencode({
    Statement = [...]
  })
}


Plan:

No diff (JSON equivalent)

Apply:

Provider sends policy

AWS updates policy version anyway

AWS treats it as a new policy version even if content is equivalent.

Scenario 5: Provider bugs / â€œforce sendâ€ updates
Example: Kubernetes provider

Provider cannot do fine-grained diffs

Sends full manifest on apply

API server mutates fields (timestamps, defaults)

Plan:

No changes


Apply:

kubectl apply-like behavior

Resource gets updated (new resourceVersion)

Scenario 6: Lifecycle settings hide the diff
resource "aws_autoscaling_group" "asg" {
  desired_capacity = 3

  lifecycle {
    ignore_changes = [desired_capacity]
  }
}


Plan:

No changes

Apply:

Provider still sends full object

Cloud provider re-syncs values

Scaling events occur

Terraform hid the diff, but the API call still happened.

Scenario 7: Refresh behavior differences

If you run:

terraform plan -refresh=false


Plan:

No changes (state is stale)

Apply:

Always refreshes state first

Detects drift

Applies corrections

Terraform did exactly what you asked â€” the plan was lying by omission.

How to detect this before it hurts you
1. Use terraform plan -out=tfplan

Then:

terraform apply tfplan


This guarantees:

Same values

Same data sources

No re-evaluation

2. Watch for â€œforces new resourceâ€ during apply

Terraform will say:

Note: Objects have changed outside of Terraform

3. Audit providers known for this behavior

High-risk providers:

Kubernetes

Helm

AWS IAM

Cloud-init

Custom providers

4. Avoid time-based or random functions in resource arguments

Use:

random_id resources

Explicit versioning

Pinned AMIs

Key mental model

Terraform plans are predictions, not guarantees.

A plan answers:

â€œGiven what I know right now, I expect no changes.â€

An apply answers:

â€œHere is what actually happens when I talk to the APIs.â€

TL;DR
Cause	Why plan missed it
Provider defaults	Applied only at update
Data source drift	Re-evaluated at apply
Time-based functions	Non-deterministic
Hidden diffs	ignore_changes
API normalization	Semantically equal â‰  identical
Refresh differences	State was stale

If you want, I can:

Break down one of these scenarios with logs

Show how to prove it with TF_LOG=TRACE

Explain how Terraform Cloud handles this differently
